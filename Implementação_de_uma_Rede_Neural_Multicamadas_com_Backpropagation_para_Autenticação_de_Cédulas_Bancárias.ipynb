{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juliadambros/Aplicacoes-Inteligencia-Artificial/blob/main/Implementa%C3%A7%C3%A3o_de_uma_Rede_Neural_Multicamadas_com_Backpropagation_para_Autentica%C3%A7%C3%A3o_de_C%C3%A9dulas_Banc%C3%A1rias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das Bibliotecas"
      ],
      "metadata": {
        "id": "kwVQbWPj0Kba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "ADzC3DQK0MbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções de ativação"
      ],
      "metadata": {
        "id": "M64z-e8cultM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_deriv_from_activation(a):\n",
        "    return a * (1 - a)\n",
        "\n",
        "def init_weights_xavier(layers):\n",
        "    # layers: ex. [4, 8, 1]\n",
        "    Ws = []\n",
        "    for i in range(len(layers) - 1):\n",
        "        fan_in = layers[i]\n",
        "        fan_out = layers[i+1]\n",
        "        # +1 no fan_in por conta do bias\n",
        "        limit = np.sqrt(6 / (fan_in + fan_out))\n",
        "        W = np.random.uniform(-limit, limit, size=(fan_in + 1, fan_out))  # inclui bias\n",
        "        Ws.append(W)\n",
        "    return Ws\n"
      ],
      "metadata": {
        "id": "2xhXnhSXun0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções da Rede Neural (MLP)"
      ],
      "metadata": {
        "id": "_Cb61liHutI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X, Ws):\n",
        "    \"\"\"\n",
        "    X: (n, d) sem a coluna de bias\n",
        "    Ws: lista de matrizes de pesos (cada uma já com linha de bias)\n",
        "    retorna: lista de ativações por camada (inclui entrada e saídas intermediárias)\n",
        "    \"\"\"\n",
        "    activations = [X]\n",
        "    A = X\n",
        "    for W in Ws:\n",
        "        A_bias = np.concatenate([A, np.ones((A.shape[0], 1))], axis=1)  # adiciona bias\n",
        "        Z = A_bias @ W\n",
        "        A = sigmoid(Z)\n",
        "        activations.append(A)\n",
        "    return activations\n",
        "\n",
        "def backprop(activations, y, Ws, lr=0.1, l2=0.0, loss=\"bce\"):\n",
        "    \"\"\"\n",
        "    BCE com saída sigmoide: delta_out = (A_L - y)\n",
        "    activations: lista de ativações de cada camada (vinda do forward).\n",
        "    y: rótulos reais.\n",
        "    Ws: lista de pesos (será atualizada).\n",
        "    lr: taxa de aprendizado.\n",
        "    l2: regularização L2 (penaliza pesos grandes).\n",
        "    loss: função de erro (padrão = Binary Cross Entropy).\n",
        "    \"\"\"\n",
        "    y = y.reshape(-1, 1)\n",
        "    A_L = activations[-1]\n",
        "    if loss == \"bce\":\n",
        "        delta = (A_L - y)  # derivada simplifica com sigmoide\n",
        "    else:\n",
        "        delta = (A_L - y) * sigmoid_deriv_from_activation(A_L)\n",
        "\n",
        "    deltas = [delta]\n",
        "    # camadas ocultas (percorrer Ws de trás p/ frente, exceto a última)\n",
        "    for i in range(len(Ws)-2, -1, -1):\n",
        "        W_next = Ws[i+1][:-1, :]  # remove linha do bias\n",
        "        A_i = activations[i+1]    # ativação da camada i+1 (já pós-sigmoide)\n",
        "        delta = (deltas[0] @ W_next.T) * sigmoid_deriv_from_activation(A_i)\n",
        "        deltas.insert(0, delta)\n",
        "\n",
        "    # atualiza pesos\n",
        "    for i in range(len(Ws)):\n",
        "        A_i = activations[i]\n",
        "        A_i_bias = np.concatenate([A_i, np.ones((A_i.shape[0], 1))], axis=1)\n",
        "        grad = A_i_bias.T @ deltas[i] / A_i.shape[0]\n",
        "        if l2 > 0:\n",
        "            # L2 só nos pesos (não no bias): zera a última linha da penalização\n",
        "            pen = np.copy(Ws[i])\n",
        "            pen[-1, :] = 0.0\n",
        "            grad += l2 * pen\n",
        "        Ws[i] -= lr * grad\n",
        "    return Ws\n",
        "\n",
        "def binary_cross_entropy(y_true, y_prob, eps=1e-12): #função de perda\n",
        "    y_true = y_true.reshape(-1, 1)\n",
        "    y_prob = np.clip(y_prob, eps, 1 - eps)\n",
        "    return np.mean(- (y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob))) #retorna um número pequeno se a rede acertou (boa previsão) e grande se errou muito.\n",
        "\n",
        "def predict(X, Ws, thr=0.5):\n",
        "    A = forward(X, Ws)[-1]\n",
        "    return (A >= thr).astype(int) #A >= 0.5, retorna 1 e se A < 0.5, retorna 0.\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = y_true.reshape(-1, 1)\n",
        "    return (y_true == y_pred).mean() * 100\n"
      ],
      "metadata": {
        "id": "HqAsoqyWwRzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregar e preparar o dataset"
      ],
      "metadata": {
        "id": "JQ6MVvhjuzpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\n",
        "cols = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
        "df = pd.read_csv(url, header=None, names=cols)\n",
        "\n",
        "X = df.iloc[:, :-1].values.astype(float) # todas as colunas, exceto a última\n",
        "y = df.iloc[:, -1].values.astype(int) # apenas a última coluna (classe)\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "# padronização usando média e desvio do treino\n",
        "mu = X_tr.mean(axis=0)\n",
        "sigma = X_tr.std(axis=0, ddof=0)\n",
        "sigma[sigma == 0] = 1.0  # evita divisão por zero\n",
        "\n",
        "X_tr = (X_tr - mu) / sigma\n",
        "X_te = (X_te - mu) / sigma\n",
        "\n",
        "print(\"Treino:\", X_tr.shape, \"Teste:\", X_te.shape, \"Positivos em teste:\", y_te.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Rpvzgou0Km",
        "outputId": "23d61dc4-d3ec-4939-a33f-5ff56caa0b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: (960, 4) Teste: (412, 4) Positivos em teste: 183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir parâmetros e treinar"
      ],
      "metadata": {
        "id": "UkOwpv0ju6Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [X_tr.shape[1],8,8,1]\n",
        "#layers = [4, 10, 8, 6, 1]\n",
        "# 4 entradas → oculta(10) → oculta(8) → oculta(6) → 1 saída\n",
        "\n",
        "lr = 1 # taxa de aprendizado\n",
        "epochs = 500\n",
        "l2 = 0.000 #penaliza pesos grandes\n",
        "\n",
        "Ws = init_weights_xavier(layers)\n",
        "history = []\n",
        "\n",
        "for ep in range(1, epochs + 1):\n",
        "    acts = forward(X_tr, Ws)\n",
        "    Ws = backprop(acts, y_tr, Ws, lr=lr, l2=l2, loss=\"bce\")\n",
        "    if ep % 50 == 0 or ep == 1:\n",
        "        loss = binary_cross_entropy(y_tr, acts[-1])\n",
        "        history.append((ep, loss))\n",
        "\n",
        "print(\"Treino finalizado.\")\n",
        "for ep, loss in history:\n",
        "    print(f\"Época {ep:4d} | Loss treino (BCE): {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEJWr5Fvu6hF",
        "outputId": "e32231aa-b7ae-40ea-eb19-13c77021e391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino finalizado.\n",
            "Época    1 | Loss treino (BCE): 0.7104\n",
            "Época   50 | Loss treino (BCE): 0.3193\n",
            "Época  100 | Loss treino (BCE): 0.0872\n",
            "Época  150 | Loss treino (BCE): 0.0522\n",
            "Época  200 | Loss treino (BCE): 0.0399\n",
            "Época  250 | Loss treino (BCE): 0.0339\n",
            "Época  300 | Loss treino (BCE): 0.0303\n",
            "Época  350 | Loss treino (BCE): 0.0280\n",
            "Época  400 | Loss treino (BCE): 0.0263\n",
            "Época  450 | Loss treino (BCE): 0.0249\n",
            "Época  500 | Loss treino (BCE): 0.0234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliar a rede"
      ],
      "metadata": {
        "id": "hmgsGHlPvBb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = predict(X_te, Ws, thr=0.5)\n",
        "acc = accuracy(y_te, y_hat)\n",
        "\n",
        "print(f\"Acurácia no teste: {acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUGJBxfvvAKo",
        "outputId": "d4cb8184-5773-4507-ae36-1458ce446669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no teste: 99.03%\n"
          ]
        }
      ]
    }
  ]
}